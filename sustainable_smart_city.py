# -*- coding: utf-8 -*-
"""Sustainable_Smart_City.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1reTo94RuchXqiWNWrpS0GgnKhnJHbpdT
"""

# Install libraries
!pip install transformers torch gradio PyPDF2 matplotlib -q

import gradio as gr
import torch, json, zipfile, os
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM
import PyPDF2
from google.colab import files
from datetime import datetime

# ----------------------------
# Load Model
# ----------------------------
MODEL_NAME = "ibm-granite/granite-3.2-2b-instruct"

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto" if torch.cuda.is_available() else None
)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token


# ----------------------------
# Core LLM Response
# ----------------------------
def generate_response(prompt: str, max_length: int = 1024) -> str:
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    if torch.cuda.is_available():
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=max_length,
            temperature=0.7,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    if response.startswith(prompt):
        response = response[len(prompt):].strip()
    return response


# ----------------------------
# Helper: PDF Reader
# ----------------------------
def extract_text_from_pdf(pdf_file) -> str:
    if pdf_file is None:
        return ""
    try:
        with open(pdf_file.name, "rb") as f:
            pdf_reader = PyPDF2.PdfReader(f)
            text = ""
            for page in pdf_reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text.strip()
    except Exception as e:
        return f"Error reading PDF: {str(e)}"


# ----------------------------
# Features
# ----------------------------
usage_log = {"eco_tips": 0, "policies": 0, "chats": 0, "footprints": 0, "renewables": 0}

def eco_tips_generator(problem_keywords: str):
    usage_log["eco_tips"] += 1
    tips = generate_response(
        f"Generate 7 practical, actionable eco-friendly tips for sustainable living related to: {problem_keywords}.",
        max_length=1000
    )
    with open("eco_tips.txt", "w") as f:
        f.write(tips)
    return tips

def policy_summarization(pdf_file, policy_text: str):
    usage_log["policies"] += 1
    if pdf_file is not None:
        content = extract_text_from_pdf(pdf_file)
        summary_prompt = f"Summarize the following policy document:\n\n{content}"
    else:
        summary_prompt = f"Summarize the following policy document:\n\n{policy_text}"

    summary = generate_response(summary_prompt, max_length=1200)
    with open("policy_summary.txt", "w") as f:
        f.write(summary)
    return summary

def sustainability_chat(user_query: str, history: list = []):
    usage_log["chats"] += 1
    context = "You are a Sustainability & Smart City AI Assistant. Answer clearly and concisely.\n"
    for q, a in history:
        context += f"Q: {q}\nA: {a}\n"
    context += f"Q: {user_query}\nA:"

    answer = generate_response(context, max_length=500)
    history.append((user_query, answer))
    return history, history

def carbon_footprint_estimator(miles, electricity, meat_meals):
    usage_log["footprints"] += 1
    # simple formula approximation
    transport = miles * 0.404  # kg CO2 per mile (car)
    energy = electricity * 0.92  # kg CO2 per kWh
    diet = meat_meals * 2.5  # kg CO2 per meal
    total = transport + energy + diet
    tips = "Your daily CO‚ÇÇ footprint is {:.2f} kg. ".format(total)
    if total > 20:
        tips += "‚ö†Ô∏è High impact! Try reducing driving or switching to renewable energy."
    else:
        tips += "‚úÖ Great! You're already quite eco-friendly."
    return tips

def renewable_energy_advisor(location, budget):
    usage_log["renewables"] += 1
    prompt = f"Suggest renewable energy solutions for a household in {location} with a budget of {budget} USD. Give practical advice."
    return generate_response(prompt, max_length=600)

def generate_dashboard():
    # Plot usage stats
    fig, ax = plt.subplots()
    ax.bar(usage_log.keys(), usage_log.values(), color="green")
    ax.set_title("Smart City Assistant Usage Analytics")
    ax.set_ylabel("Tasks Completed")
    plt.xticks(rotation=30)
    fig.savefig("dashboard.png")
    return "dashboard.png"

def export_all():
    # Create ZIP file
    zip_name = f"smart_city_outputs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
    with zipfile.ZipFile(zip_name, 'w') as zipf:
        for f in ["eco_tips.txt", "policy_summary.txt"]:
            if os.path.exists(f):
                zipf.write(f)
    files.download(zip_name)
    return f"‚úÖ Exported all results as {zip_name}"


# ----------------------------
# Gradio Interface
# ----------------------------
with gr.Blocks(theme=gr.themes.Soft()) as app:
    gr.Markdown("# üåç Sustainable Smart City AI Assistant")

    with gr.Tabs():
        with gr.TabItem("üå± Eco Tips Generator"):
            keywords_input = gr.Textbox(label="Keywords", placeholder="e.g., plastic, water waste")
            generate_tips_btn = gr.Button("Generate Eco Tips")
            tips_output = gr.Textbox(label="Tips", lines=12)
            generate_tips_btn.click(eco_tips_generator, inputs=keywords_input, outputs=tips_output)

        with gr.TabItem("üìú Policy Summarization"):
            pdf_upload = gr.File(label="Upload Policy PDF", file_types=[".pdf"])
            policy_text_input = gr.Textbox(label="Or Paste Policy", lines=5)
            summarize_btn = gr.Button("Summarize Policy")
            summary_output = gr.Textbox(label="Summary", lines=15)
            summarize_btn.click(policy_summarization, inputs=[pdf_upload, policy_text_input], outputs=summary_output)

        with gr.TabItem("üí¨ Q&A Chatbot"):
            chatbot = gr.Chatbot()
            query = gr.Textbox(placeholder="Ask about sustainability...", label="Your Question")
            send_btn = gr.Button("Send")
            state = gr.State([])
            send_btn.click(sustainability_chat, inputs=[query, state], outputs=[chatbot, state])

        with gr.TabItem("üåé Carbon Footprint Estimator"):
            miles = gr.Number(label="Miles driven per day")
            electricity = gr.Number(label="Electricity use (kWh/day)")
            meat = gr.Number(label="Meat meals per day")
            calc_btn = gr.Button("Estimate Footprint")
            footprint_out = gr.Textbox(label="Result", lines=5)
            calc_btn.click(carbon_footprint_estimator, inputs=[miles, electricity, meat], outputs=footprint_out)

        with gr.TabItem("üîÜ Renewable Energy Advisor"):
            location = gr.Textbox(label="Location")
            budget = gr.Number(label="Budget (USD)")
            energy_btn = gr.Button("Get Recommendations")
            energy_out = gr.Textbox(label="Energy Advice", lines=10)
            energy_btn.click(renewable_energy_advisor, inputs=[location, budget], outputs=energy_out)

        with gr.TabItem("üìä Analytics Dashboard"):
            dash_btn = gr.Button("Generate Usage Dashboard")
            dash_img = gr.Image(label="Usage Stats")
            dash_btn.click(generate_dashboard, outputs=dash_img)

        with gr.TabItem("üìÇ Export Center"):
            export_btn = gr.Button("Export All Results (ZIP)")
            export_msg = gr.Textbox(label="Export Status")
            export_btn.click(export_all, outputs=export_msg)

app.launch(share=True)